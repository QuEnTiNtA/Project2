{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "=> Loading checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import UNET\n",
    "from utils import load_checkpoint\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "load_checkpoint(torch.load(\"add1024_5000epoch.pth\"), model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:29<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils import RoadDataset, get_transform\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "train_dir = \"data/train_images\"\n",
    "train_maskdir = \"data/train_masks\"\n",
    "\n",
    "dataset = RoadDataset(\n",
    "    image_dir=train_dir,\n",
    "    mask_dir=train_maskdir,\n",
    "    transform=get_transform(train=True),\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1,\n",
    "                    pin_memory=True, shuffle=False, num_workers=2)     \n",
    "\n",
    "p_list, r_list = [0.0 for i in range(len(dataset))], [0.0 for i in range(len(dataset))]\n",
    "n_valid = [0 for i in range(len(dataset))]\n",
    "y_pos_ratio = []\n",
    "for epoch in tqdm(range(50)):\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=DEVICE)\n",
    "            y = y.to(device=DEVICE).unsqueeze(1)\n",
    "            y_pos_ratio.append(y.sum().item() / y.numel())\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            TP = ((preds == 1)*(y==1)).sum()\n",
    "            FP = ((preds == 1)*(y==0)).sum()\n",
    "            FN = ((preds == 0)*(y==1)).sum()\n",
    "            recall = TP/(TP+FN)\n",
    "            precision = TP/(TP+FP)\n",
    "            if math.isnan(recall) or math.isnan(precision):\n",
    "                continue\n",
    "            p_list[batch_idx] += precision\n",
    "            r_list[batch_idx] += recall\n",
    "            n_valid[batch_idx] += 1\n",
    "p_list = [p_list[i] / n_valid[i] for i in range(len(dataset))]\n",
    "r_list = [r_list[i] / n_valid[i] for i in range(len(dataset))]\n",
    "f1_list = [2*r_list[i]*p_list[i]/(r_list[i]+p_list[i]) for i in range(len(p_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10, 18, 20, 22, 26, 27, 28, 29, 30, 31, 32, 40, 52, 74, 76, 77, 85, 87, 90, 91, "
     ]
    }
   ],
   "source": [
    "for i in range(len(f1_list)):\n",
    "    if f1_list[i].item() < 0.989:\n",
    "        # print(i, f1_list[i].item())\n",
    "        print(f'{i}, ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.9904438853263855\n",
      "10 0.9087799787521362\n",
      "17 0.9892675280570984\n",
      "20 0.8747090101242065\n",
      "22 0.9857665300369263\n",
      "26 0.9776500463485718\n",
      "27 0.9643473625183105\n",
      "29 0.9784762859344482\n",
      "30 0.9832307696342468\n",
      "31 0.9860295653343201\n",
      "32 0.968249499797821\n",
      "43 0.9902804493904114\n",
      "58 0.991472601890564\n",
      "60 0.989358127117157\n",
      "64 0.9899277091026306\n",
      "74 0.9859753847122192\n",
      "76 0.9255867600440979\n",
      "77 0.9745124578475952\n",
      "87 0.9839822053909302\n",
      "90 0.9850777387619019\n",
      "91 0.9420167803764343\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(f1_list)):\n",
    "    if p_list[i].item() < 0.99:\n",
    "        print(i, r_list[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20964930747922517"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pos_ratio) / len(y_pos_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "512d8afb2191382feab08689ffd3568f0534553afd778b345ebffea1d046c029"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
